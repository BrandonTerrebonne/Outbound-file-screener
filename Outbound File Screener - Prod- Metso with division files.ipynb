{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from db import DB\n",
    "from db import list_profiles\n",
    "from datetime import *\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from openpyxl import Workbook\n",
    "from openpyxl import load_workbook\n",
    "import xlsxwriter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.max_rows = 999\n",
    "pd.options.display.max_columns = 999\n",
    "\n",
    "# User config\n",
    "user_config = {\n",
    "    'base_path': r'C:\\Users\\brandon.terrebonne\\Desktop\\outbound_file_screening'\n",
    "}\n",
    "\n",
    "## Defining fucntions ##\n",
    "# Sorts out instances where the buyer sends eslap files containing non-compliant field names (e.g. 'INVOICEID' vs 'invoice_id')\n",
    "def buyer_outbound_mappings(buyer_configs_data, buyer_name, table_field_name, eslap_col_names):\n",
    "    buyer_data = buyer_configs_data[buyer_configs_data['upload_directory'] == buyer_name]\n",
    "    index_list = buyer_data.index.tolist()\n",
    "    buyer_index = index_list[0]\n",
    "    pre_transform_col_names = []\n",
    "    pre_transform_col_names_values = []\n",
    "    for x in eslap_col_names:\n",
    "        try:\n",
    "            trans_name = buyer_data.loc[buyer_index][table_field_name]['TransformItems'][x]['IncomingColumnName']\n",
    "            pre_transform_col_names.append(trans_name)\n",
    "            pre_transform_col_names_values.append(x)\n",
    "        except:\n",
    "            pass\n",
    "    file_mapping_dict = dict(zip(pre_transform_col_names, pre_transform_col_names_values))\n",
    "    return file_mapping_dict\n",
    "\n",
    "\n",
    "# Given a DF and specifying a field from that DF that contains JSON/dictionary data, this will append the JSON data to the existing DF\n",
    "def dict_fields_to_df(original_df, dictionary_field_name): \n",
    "    dictionary_data = pd.DataFrame(list(original_df[dictionary_field_name]))\n",
    "    original_df_field_names = list(original_df.columns.values)\n",
    "    dictionary_field_names = list(dictionary_data.columns.values)\n",
    "    for col in dictionary_field_names:\n",
    "        if col in original_df_field_names:\n",
    "            pass\n",
    "        else:\n",
    "            original_df[col] = dictionary_data[col]\n",
    "    return original_df\n",
    "\n",
    "\n",
    "# changes encoding/decoding to uft8 - helpful when solving \"UnicodeDecodeError: 'utf8' codec can't decode byte...\". Should only be used for cols with strings, allegedly.\n",
    "# source: http://stackoverflow.com/questions/18645401/python-pandas-to-excel-utf8-codec-cant-decode-byte\n",
    "def changeencode(data, cols):  \n",
    "    for col in cols:\n",
    "        data[col] = data[col].str.decode('iso-8859-1').str.encode('utf-8')\n",
    "    return data \n",
    "\n",
    "\n",
    "# User input to specify which database to query\n",
    "active_db = raw_input('Which Database (prod, uat, guat, redshift or devload)?  ')\n",
    "while True:\n",
    "    if str(active_db) == 'prod':\n",
    "        db = DB(profile='production')\n",
    "        break\n",
    "    elif str(active_db) == 'uat':\n",
    "        db = DB(profile='uat')\n",
    "        break\n",
    "    elif str(active_db) == 'redshift':\n",
    "        db = DB(profile='redshift')\n",
    "        break\n",
    "    elif str(active_db) == 'devload':\n",
    "        db = DB(profile='devload')\n",
    "        break\n",
    "    elif str(active_db) == 'guat':\n",
    "        db = DB(profile='guat')\n",
    "        break\n",
    "    else:\n",
    "        print 'Invalid response - please try again...'\n",
    "        active_db = raw_input('Which Database (prod, uat, redshift or devload)? ')\n",
    "\n",
    "# User input to specify buyer name - needed to know which C2FO Admin buyer config to look at\n",
    "buyer_configs = db.query(\"\"\"\n",
    "                        select *\n",
    "                        from fileset_configuration\n",
    "                        ;\"\"\"\n",
    "                        )\n",
    "buyer_names_list = sorted(buyer_configs['upload_directory'].tolist()) # Prints a list of all possible buyer names\n",
    "print buyer_names_list\n",
    "buyer_name_input = raw_input('\\nBuyer Name: ').lower()\n",
    "while True:\n",
    "    if buyer_name_input in buyer_names_list:\n",
    "        buyer_config = buyer_configs[buyer_configs['upload_directory'] == buyer_name_input]\n",
    "        buyer_index_value = list(buyer_config.index.values)\n",
    "        break\n",
    "    else:\n",
    "        print 'Invalid response - please try again...'\n",
    "        buyer_name_input = raw_input('\\nBuyer Name: ').lower()\n",
    "\n",
    "# Load buyer's outbound files to pandas dataframes \n",
    "dir_files = [f for f in listdir(user_config['base_path']) if isfile(join(user_config['base_path'], f))]\n",
    "dir_files_final = [s for s in dir_files if s[0] != '~'] # Makes sure we don't pull an excel litter file\n",
    "\n",
    "alternative_organization_filename = str(buyer_config['organization_filename'][buyer_index_value[0]]) #pull alternative eslap file names from buyer config in C2FO Admin\n",
    "alternative_invoice_filename = str(buyer_config['invoice_filename'][buyer_index_value[0]])\n",
    "alternative_user_filename = str(buyer_config['user_filename'][buyer_index_value[0]])\n",
    "\n",
    "for file_name in dir_files_final:\n",
    "    if ('invoice' in file_name.lower()) or (alternative_invoice_filename in file_name):\n",
    "        invoice_file_name = file_name\n",
    "        invoice_file_path = user_config['base_path'] + '\\\\' + file_name\n",
    "        invoice_file = pd.read_csv(invoice_file_path)\n",
    "    elif ('organization' in file_name.lower()) or (alternative_organization_filename in file_name):\n",
    "        org_file_name = file_name\n",
    "        org_file_path = user_config['base_path'] + '\\\\' + file_name\n",
    "        org_file = pd.read_csv(org_file_path)\n",
    "    elif ('user' in file_name.lower()) or (alternative_user_filename in file_name):\n",
    "        user_file_name = file_name\n",
    "        user_file_path = user_config['base_path'] + '\\\\' + file_name\n",
    "        user_file = pd.read_csv(user_file_path)\n",
    "    else:\n",
    "        print 'There is at least one unknown file in %s' % (user_config['base_path'])\n",
    "\n",
    "# Renaming *invoice file fields if the buyer does not send eslap compliant field names... this is done by checking the buyer config via the C2FO database \n",
    "# ToDo: extend this to over and user file fields\n",
    "invoice_file_fields = invoice_file.columns.values.tolist()\n",
    "eslap_invoice_fields = ['company_id', \n",
    "                 'division_id',\n",
    "                 'invoice_id',\n",
    "                 'amount',\n",
    "                 'currency',\n",
    "                 'payment_due_date',\n",
    "                 'transaction_type',\n",
    "                 'transaction_date',\n",
    "                 'voucher_id',\n",
    "                 'payment_term',\n",
    "                 'payment_method',\n",
    "                 'adj_invoice_id',\n",
    "                 'adjustment_reason_code',\n",
    "                 'vat_amount']\n",
    "\n",
    "invoice_col_names_transformed = buyer_outbound_mappings(buyer_configs, buyer_name_input, 'invoice_map', eslap_invoice_fields) #Will need updating onces the scope of this code is extended to org/user files\n",
    "final_col_name_list = []\n",
    "for col in invoice_file_fields:\n",
    "    if col in invoice_col_names_transformed:\n",
    "        final_col_name_list.append(invoice_col_names_transformed[col])\n",
    "    else:\n",
    "        final_col_name_list.append(col)\n",
    "invoice_file.rename(columns=dict(zip(invoice_file_fields, final_col_name_list)), inplace=True)\n",
    "invoice_file['original_index'] = invoice_file.index # Creates new column to keep track of each row's original index (used in the creation of binary fields)\n",
    "\n",
    "# Trim column names\n",
    "# https://github.com/BrandonTerrebonne/Outbound-file-screener/issues/6\n",
    "invoice_file_cols = list(invoice_file.columns.values)\n",
    "new_invoice_file_cols = [x.strip() for x in invoice_file_cols]\n",
    "invoice_file.columns = new_invoice_file_cols\n",
    "\n",
    "# Formatting invoice file columns\n",
    "invoice_file['amount'] = invoice_file['amount'].astype(str)\n",
    "invoice_file['adj_invoice_id'] = invoice_file['adj_invoice_id'].astype(str)\n",
    "invoice_file['invoice_id'] = invoice_file['invoice_id'].astype(str)\n",
    "\n",
    "# Create two new DFs for each transaction type (1 and 2)\n",
    "trans_type1_df = invoice_file[invoice_file['transaction_type'] == 1]\n",
    "trans_type1_df['amount'] = trans_type1_df['amount'].astype(float)\n",
    "trans_type2_df = invoice_file[invoice_file['transaction_type'] == 2]\n",
    "trans_type2_df['amount'] = trans_type2_df['amount'].astype(float)\n",
    "invoice_file_rowcount = len(invoice_file.index)\n",
    "trans_type1_df_rowcount = len(trans_type1_df.index)\n",
    "trans_type2_df_rowcount = len(trans_type2_df.index)\n",
    "\n",
    "# Matched and unmatched adjustments\n",
    "trans_type2_df['adj_invoice_id'] = trans_type2_df['adj_invoice_id'].astype(str)\n",
    "unmatched_adj_df = trans_type2_df[trans_type2_df['adj_invoice_id'] == 'nan']\n",
    "unmatched_count = len(unmatched_adj_df.index)\n",
    "matched_adj_df = trans_type2_df[trans_type2_df['adj_invoice_id'] != 'nan']\n",
    "matched_count = len(matched_adj_df.index)\n",
    "\n",
    "# Future dated invoices, unmatched adjustments and matched adjustments\n",
    "todays_date = datetime.today().strftime('%Y-%m-%d') # Get today's date in YYYY-MM-DD format\n",
    "trans_type1_df['payment_due_date'] = trans_type1_df['payment_due_date'].astype(datetime) # Future dated invoices\n",
    "future_dated_type1 = trans_type1_df[trans_type1_df['payment_due_date'] > todays_date]\n",
    "future_dated_type1_count = len(future_dated_type1.index)\n",
    "matched_adj_df['payment_due_date'] = matched_adj_df['payment_due_date'].astype(datetime) # Future dated matched adjustments\n",
    "future_dated_matched_df = matched_adj_df[matched_adj_df['payment_due_date'] > todays_date]\n",
    "future_dated_matched_count = len(future_dated_matched_df.index)\n",
    "future_dated_matched_df_original_index_list = list(future_dated_matched_df['original_index'])\n",
    "invoice_file['future_dated_matched_adj'] = np.where(invoice_file['original_index'].isin(future_dated_matched_df_original_index_list), 1, 0) \n",
    "unmatched_adj_df['payment_due_date'] = unmatched_adj_df['payment_due_date'].astype(datetime) # Future dated unmatched adjustments\n",
    "future_dated_unmatched_df = unmatched_adj_df[unmatched_adj_df['payment_due_date'] > todays_date]\n",
    "future_dated_unmatched_count = len(future_dated_unmatched_df.index) \n",
    "future_dated_unmatched_df_original_index_list = list(future_dated_unmatched_df['original_index']) \n",
    "invoice_file['future_dated_unmatched_adj'] = np.where(invoice_file['original_index'].isin(future_dated_unmatched_df_original_index_list), 1, 0) \n",
    "\n",
    "# Matched adjs where their corresponding invoices are missing from the invoice file\n",
    "inv_id_list = invoice_file['invoice_id'].tolist()\n",
    "adj_inv_id_list = matched_adj_df['adj_invoice_id'].tolist()\n",
    "valid_matched_count = len([i for i in adj_inv_id_list if i in inv_id_list])\n",
    "invalid_matched = [i for i in adj_inv_id_list if i not in inv_id_list]\n",
    "invalid_matched_df = invoice_file[invoice_file['adj_invoice_id'].isin(invalid_matched)]\n",
    "invalid_matched_df_original_index_list = list(invalid_matched_df['original_index']) \n",
    "invoice_file['matched_adj_missing_invoice'] = np.where(invoice_file['original_index'].isin(invalid_matched_df_original_index_list), 1, 0)\n",
    "\n",
    "# Number of records with 'amount' equal to zero\n",
    "invoice_file['amount'] = invoice_file['amount'].astype(float)\n",
    "zero_amounts = invoice_file[invoice_file['amount'] == 0]\n",
    "zero_amounts_count = len(zero_amounts.index)\n",
    "zero_amounts_original_index_list = list(zero_amounts['original_index']) \n",
    "invoice_file['amount_is_zero'] = np.where(invoice_file['original_index'].isin(zero_amounts_original_index_list), 1, 0)\n",
    "\n",
    "# Number of records incorrectly applying transaction_type logic\n",
    "negative_trans_type1s = trans_type1_df[trans_type1_df['amount'] < 0] # Negative transaction_type = 1\n",
    "negative_trans_type1s_original_index_list = list(negative_trans_type1s['original_index']) \n",
    "invoice_file['negative_type_1'] = np.where(invoice_file['original_index'].isin(negative_trans_type1s_original_index_list), 1, 0) \n",
    "positive_trans_type2s = trans_type2_df[trans_type2_df['amount'] > 0] # Positive transaction_type = 1\n",
    "positive_trans_type2s_original_index_list = list(positive_trans_type2s['original_index']) \n",
    "invoice_file['positive_type_2'] = np.where(invoice_file['original_index'].isin(positive_trans_type2s_original_index_list), 1, 0) \n",
    "\n",
    "# Invoices with adjusted invoice IDs (aka matched invoices or invoice_with_adj_inv_id)\n",
    "matched_inv_df = trans_type1_df[trans_type1_df['adj_invoice_id'] != 'nan']\n",
    "matched_inv_count = len(matched_inv_df.index)\n",
    "matched_inv_df_original_index_list = list(matched_inv_df['original_index']) \n",
    "invoice_file['invoice_with_adj_inv_id'] = np.where(invoice_file['original_index'].isin(matched_inv_df_original_index_list), 1, 0) \n",
    "    \n",
    "# List all invoice file fields that are populated < 1 time\n",
    "inv_file_fields = list(invoice_file.columns.values) # Get list of field names\n",
    "empty_fields = []\n",
    "inv_file_len = len(invoice_file.index) # Get row count of invoice file\n",
    "for x in inv_file_fields: # Returns list of invoice file files that were not populated\n",
    "    invoice_file[x] = invoice_file[x].astype(str)\n",
    "    new_df = invoice_file[invoice_file[x] == 'nan']\n",
    "    if len(new_df.index) == inv_file_len:\n",
    "        empty_fields.append(x)\n",
    "\n",
    "# Creating .xlsx doc to output the summary\n",
    "summary_file_path = user_config['base_path'] + '\\\\' + 'OUTBOUND_FILE_SUMMARY_' + (time.strftime('%Y%m%d')) + '.xlsx'\n",
    "workbook = xlsxwriter.Workbook(summary_file_path)\n",
    "workbook.close()\n",
    "wb = load_workbook(summary_file_path)\n",
    "ws1 = wb.create_sheet('Summary', 0) # insert at first position\n",
    "for i in range(1,101):\n",
    "    for j in range(1,101):\n",
    "        ws1.cell(row=i, column=j)\n",
    "workbook = xlsxwriter.Workbook(summary_file_path)\n",
    "worksheet = workbook.add_worksheet()\n",
    "workbook.close()\n",
    "\n",
    "# Writing Invoice File summary to Excel doc\n",
    "ws1['A1'] = '--- Invoice File Summary ---'\n",
    "ws1['A2'] = 'File name: %s' % (invoice_file_name)\n",
    "ws1['A3'] = 'Number of records in the file: %s' % (invoice_file_rowcount)\n",
    "ws1['A4'] = 'Number of invoices: %s' % (trans_type1_df_rowcount)\n",
    "ws1['A5'] = 'Number of adjustments: %s' % (trans_type2_df_rowcount)\n",
    "ws1['A6'] = 'Number of unmatched adjustments: %s' % (unmatched_count)\n",
    "ws1['A7'] = 'Number of matched adjusments: %s' % (matched_count)\n",
    "ws1['A9'] = '--- Age Summary for %s ---' % (todays_date)\n",
    "ws1['A10'] = 'Number of future dated invoices: %s' % (future_dated_type1_count)\n",
    "ws1['A11'] = 'Number of future dated unmatched adjustments: %s' % (future_dated_unmatched_count)\n",
    "ws1['A12'] = 'Number of future dated matched adjustments: %s' % (future_dated_matched_count)\n",
    "ws1['A14'] = '--- Issue Summary ---'\n",
    "if len(invalid_matched_df.index) > 0:\n",
    "    ws1['A15'] = 'WARNING - Number of matched adjustments missing their corresponding invoices: %s' % (len(invalid_matched_df.index))\n",
    "else:\n",
    "    ws1['A15'] = 'Passed - Number of matched adjustments missing their corresponding invoices: %s' % (len(invalid_matched_df.index))\n",
    "if zero_amounts_count > 0:\n",
    "    ws1['A16'] = 'WARNING - Number of records with \\'amount\\' equal to zero: %s' % (zero_amounts_count)\n",
    "else:\n",
    "    ws1['A16'] = 'Passed - Number of records with \\'amount\\' equal to 0.00: %s' % (zero_amounts_count)\n",
    "if len(negative_trans_type1s.index) > 0:\n",
    "    ws1['A17'] = 'WARNING - Number of NEGATIVE transaction_type 1s: %s' % (len(negative_trans_type1s.index))\n",
    "else: \n",
    "    ws1['A17'] = 'Passed - Number of NEGATIVE transaction_type 1s: %s' % (len(negative_trans_type1s.index))\n",
    "if len(positive_trans_type2s.index) > 0:\n",
    "    ws1['A18'] = 'WARNING - Number of POSITIVE transaction_type 2s: %s' % (len(positive_trans_type2s.index))\n",
    "else:\n",
    "    ws1['A18'] = 'Passed - Number of POSITIVE transaction_type 2s: %s' % (len(positive_trans_type2s.index))\n",
    "if matched_inv_count > 0:\n",
    "    ws1['A19'] = \"Warning - Number of transaction_type 1s with adj_invoice_ids: %s\" % (matched_inv_count)\n",
    "else:\n",
    "    ws1['A19'] = \"Passed - No invoices found with adj_invoice_id field populated\"\n",
    "if not empty_fields:\n",
    "    ws1['A20'] = 'All fields are populated at least once.'\n",
    "if empty_fields:\n",
    "    ws1['A20'] = 'Warning - Fields not populated: %s' % (empty_fields)\n",
    "\n",
    "# Writing Org File summary to Excel doc\n",
    "ws1['A22'] = '--- Organization File Summary ---'\n",
    "try:\n",
    "    if org_file.index[0] != 0: # When data unintentionally shifts due to improper CSV format, the index will SOMETIMES default to the data that was intended for the first column. \n",
    "        ws1['A23'] = 'WARNING - %s may NOT be a valid CSV file!!!' % (org_file_name) # In which case, the assumption is that the first index value will not be 0\n",
    "    else:\n",
    "        ws1['A23'] = 'Passed - %s looks like a valid CSV file' % (org_file_name)\n",
    "except (NameError, IndexError):\n",
    "    ws1['A23'] = 'No organization file found or file has no data'\n",
    "\n",
    "# Writing User File summary to Excel doc\n",
    "ws1['A30'] = '--- User File Summary ---'\n",
    "try:\n",
    "    if user_file.index[0] != 0:\n",
    "        ws1['A31'] = 'WARNING - %s may NOT be a valid CSV file!!!' % (user_file_name)\n",
    "    else:\n",
    "        ws1['A31'] = 'Passed - %s looks like a valid CSV file' % (user_file_name)\n",
    "except (NameError, IndexError):\n",
    "    ws1['A31'] = 'No user file found or file has no data'\n",
    "wb.save(summary_file_path)\n",
    "\n",
    "# DFs to excel worksheets... http://stackoverflow.com/questions/20219254/how-to-write-to-an-existing-excel-file-without-overwriting-data-using-pandas\n",
    "book = load_workbook(summary_file_path)\n",
    "writer = pd.ExcelWriter(summary_file_path, engine='openpyxl')\n",
    "writer.book = book\n",
    "writer.sheets = dict((ws.title, ws) for ws in book.worksheets)\n",
    "inv_file_tab_name = str(invoice_file_name)[:30]\n",
    "invoice_file.replace(to_replace= 'nan', value= '', inplace= True)\n",
    "\n",
    "# Fixes pd.to_excel issues with encoding/decoding - related to issue with anthem test file on 20170301\n",
    "try:\n",
    "    invoice_file.to_excel(writer, sheet_name= inv_file_tab_name, index=False)\n",
    "except UnicodeDecodeError:\n",
    "    invoice_file_cols = list(invoice_file.columns.values)\n",
    "    invoice_file = changeencode(invoice_file, invoice_file_cols)\n",
    "    invoice_file.to_excel(writer, sheet_name= inv_file_tab_name, index=False)\n",
    "\n",
    "# Eligible AP @ supplier level\n",
    "buyer_division_id = int(buyer_configs[buyer_configs['upload_directory'] == buyer_name_input]['maker_id'])\n",
    "takers_markets_query = \"\"\"\n",
    "select mto.company_id, t.taker_maker_id as division_id, t.taker_division_name as company_name, t.eligible_invoice_amount as eligible_amount, \n",
    "t.eligible_invoice_count as eligible_count, t.matched_adjustment_count as matched_adj_count, t.unmatched_adjustment_count as unmatched_adj_count, \n",
    "t.currency, t.eligible_dpe_weighted_avg, t.min_eligible_dpe, t.max_eligible_dpe, t.is_participating, t.taker_id,  t.market_id, t.market_type\n",
    "from takers_markets t\n",
    "join makers_takers d\n",
    "on t.taker_id = d.taker_id\n",
    "full outer join makers_takers_organizations mto\n",
    "on d.taker_organization_id = mto.taker_id\n",
    "where t.maker_id = {} and eligible_invoice_count > 0\n",
    "order by t.eligible_invoice_amount desc\n",
    ";\"\"\".format(buyer_division_id)\n",
    "takers_markets = db.query(takers_markets_query)\n",
    "# If the buyer doesn't send division files, company_id and division_id \n",
    "# will be equal and we will drop the division_id series from the DF\n",
    "if takers_markets['company_id'].equals(takers_markets['division_id']):\n",
    "    takers_markets = takers_markets.drop('division_id', axis=1)\n",
    "takers_markets.to_excel(writer, sheet_name= 'DB - Eligible AP', index= False)\n",
    "\n",
    "#Invoice table - ToDo: ADD PAY_DATE!!!\n",
    "invoices_query = \"\"\"\n",
    "select company_id, voucher_id as invoice_id, amount, earn, discounted_amount, adjustment_amount, vat_amount, due_date, cleared_date,\n",
    "CAST(created as DATE), CAST(updated as DATE), currency, adj_invoice_id, transaction_type, is_cleared, is_awarded, is_paid, is_past_due, \n",
    "is_in_cash_pool, is_pending_clear, is_reserved, is_ineligible_ep, is_ineligible_ar, taker_excluded, maker_excluded, \n",
    "maker_excluded_for_today, taker_excluded_for_today, market_id, eslap\n",
    "from invoice\n",
    "where maker_id = {}\n",
    "order by cleared_date desc\n",
    ";\"\"\".format(buyer_division_id)\n",
    "invoice_table_data = db.query(invoices_query)\n",
    "dict_fields_to_df(invoice_table_data,'eslap')\n",
    "invoice_table_data.drop('eslap', axis=1, inplace=True)\n",
    "invoice_table_data.to_excel(writer, sheet_name= 'DB - Invoice Table', index= False)\n",
    "\n",
    "# Supplier reserves - This will return an empty DF is no reserve data has been loaded\n",
    "reserves_query = \"\"\"\n",
    "select mto.company_id, mt.division_id as division_id, mtr.taker_id as DB_taker_id, mtr.reserve_percentage, mtr.reserve_amount, mtr.invoice_priority\n",
    ", mtr.run_before_adjustments, mtr.allow_eslap_updates, CAST(mtr.created as DATE), CAST(mtr.updated as DATE), mtr.reserve_reason\n",
    "from market m\n",
    "join market_taker_reserve mtr\n",
    "on m.id = mtr.market_id\n",
    "join makers_takers mt\n",
    "on mt.taker_id = mtr.taker_id\n",
    "full outer join makers_takers_organizations mto\n",
    "on mt.taker_organization_id = mto.taker_id\n",
    "where m.maker_id = {}\n",
    ";\"\"\".format(buyer_division_id)\n",
    "supplier_reserves = db.query(reserves_query)\n",
    "# If the buyer doesn't send division files, company_id and division_id \n",
    "# will be equal and we will drop the division_id series from the DF\n",
    "if supplier_reserves['company_id'].equals(supplier_reserves['division_id']):\n",
    "    supplier_reserves = supplier_reserves.drop('division_id', axis=1)\n",
    "supplier_reserves = supplier_reserves.drop_duplicates()\n",
    "supplier_reserves.to_excel(writer, sheet_name= 'DB - Supplier Reserves', index= False)\n",
    "\n",
    " # Removes the random blank sheet that somehow always gets created (?!?)\n",
    "sh= book.get_sheet_by_name('Sheet1')\n",
    "book.remove_sheet(sh)\n",
    "writer.save()\n",
    "\n",
    "# Print summary (in case the invoice file is too big to open in excel)\n",
    "print \"\\n---Invoice File Summary---\\nFile name: %s\" % (invoice_file_name)\n",
    "print \"Number of records in the file: %s\" % (invoice_file_rowcount)\n",
    "print \"Number of invoices: %s\" % (trans_type1_df_rowcount)\n",
    "print \"Number of adjustments: %s\" % (trans_type2_df_rowcount)\n",
    "print \"Number of unmatched adjustments: %s\" % (unmatched_count)\n",
    "print \"Number of matched adjusments: %s\\n\" % (matched_count)\n",
    "print \"---Invoice File Age Summary for %s---\\nNumber of future dated invoices: %s\" % (todays_date, future_dated_type1_count)\n",
    "print \"Number of future dated matched adjustments: %s\" % (future_dated_matched_count)\n",
    "print \"Number of future dated unmatched adjustments:%s\\n\\n---Invoice File Issue Summary---\" % (future_dated_unmatched_count)\n",
    "if len(invalid_matched_df.index) > 0:\n",
    "    print \"Warning - Number of matched adjustments that do not have their corresponding invoices present: %s\" % (len(invalid_matched_df.index))\n",
    "else:\n",
    "    print \"Passed - All matched adjustments have their corresponding invoices present\"\n",
    "if zero_amounts_count > 0:\n",
    "    print \"Warning - Number of records with 'amount' equal to zero: %s\" % (zero_amounts_count)\n",
    "else:\n",
    "    print \"Passed - No records with amount = 0.00\"\n",
    "if len(negative_trans_type1s.index) > 0:\n",
    "    print \"Warning - Number of NEGATIVE transaction_type 1s: %s\" % (len(negative_trans_type1s.index))\n",
    "else:\n",
    "    print \"Passed - All transaction_type 1s are positive\"\n",
    "if len(positive_trans_type2s.index) > 0:\n",
    "    print \"Warning - Number of POSITIVE transaction_type 2s: %s\" % (len(positive_trans_type2s.index))\n",
    "else:\n",
    "    print \"Passed - All transaction_type 2s are negative\"\n",
    "if matched_inv_count > 0:\n",
    "    print \"Warning - Number of transaction_type 1s with adj_invoice_ids: %s\" % (matched_inv_count)\n",
    "else:\n",
    "    print \"Passed - No invoices found with adj_invoice_id field populated\"\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x) # Print currency pivot table --> ToDo: Figure out how to add this to the excel doc\n",
    "invoice_file['amount'] = invoice_file['amount'].astype(float)\n",
    "try:\n",
    "    currency_pivot = invoice_file.pivot_table(index=['currency'], values=['amount'], aggfunc = np.sum)\n",
    "    print \"\\n---Invoice File Currency Breakdown---\\n%s\" % (currency_pivot)\n",
    "except KeyError:\n",
    "    print \"amount or currency field left blank for at least one record - cannot generate currency pivot\"\n",
    "\n",
    "print '\\nDone!'\n",
    "\n",
    "# Excel for costcouk =CONCAT(LEFT(E2,4),\"-\",MID(E2,5,2),\"-\",RIGHT(E2,2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
